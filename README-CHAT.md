# ğŸ¤– Walletfy AI - Asistente de Chat Inteligente y Contextualizado

## ğŸ“‹ DescripciÃ³n del Proyecto

ExtensiÃ³n de la aplicaciÃ³n web Walletfy que integra un **asistente de chat conversacional inteligente**. El asistente utiliza los datos financieros especÃ­ficos del usuario para proporcionar anÃ¡lisis personalizados, consejos y respuestas contextualizadas sobre sus finanzas.

## âœ… Funcionalidades Implementadas

### 1. ğŸ¯ IntegraciÃ³n de Componente de Chat con LLM
- âœ… **Interfaz de chat intuitiva y moderna** con diseÃ±o responsive
- âœ… **Motor conversacional** impulsado por LLM con servidor de prueba personalizado
- âœ… **ComunicaciÃ³n asÃ­ncrona** usando React Query para gestiÃ³n de estado
- âœ… **Manejo de errores** y estados de carga elegantes

### 2. ğŸ“Š ContextualizaciÃ³n de Datos de la AplicaciÃ³n
- âœ… **Objeto JSON estructurado y optimizado** con datos de Walletfy:
  ```json
  {
    "initialBalance": 3000,
    "currentBalance": 2850.75,
    "totalEvents": 15,
    "totalIncome": 2500.00,
    "totalExpenses": 2649.25,
    "monthlyData": [...],
    "recentEvents": [...]
  }
  ```
- âœ… **ContextualizaciÃ³n automÃ¡tica** que incluye:
  - Balance inicial y actual del usuario
  - Totales de ingresos y gastos
  - Datos mensuales detallados con balances acumulados
  - Ãšltimas 10 transacciones con fechas y detalles

### 3. âš¡ GestiÃ³n Inteligente de la Carga del Modelo
- âœ… **Estado de carga** visual mientras se prepara el contexto
- âœ… **DeshabilitaciÃ³n automÃ¡tica** del input hasta que el contexto estÃ© listo
- âœ… **InformaciÃ³n del estado** mostrada en el header (balance actual, eventos totales)

### 4. ğŸ”„ InteracciÃ³n AsÃ­ncrona con el LLM
- âœ… **EnvÃ­o asÃ­ncrono** de consultas sin bloquear la UI
- âœ… **Indicadores de progreso** personalizados ("Analizando tus datos financieros...")
- âœ… **Manejo de timeouts** configurables segÃºn el nivel de razonamiento
- âœ… **Respuestas completas** tras Ãºnico envÃ­o

### 5. âš™ï¸ PersonalizaciÃ³n del Comportamiento del LLM
- âœ… **System prompt especializado** para finanzas personales
- âœ… **Panel de configuraciÃ³n completo** con controles para:
  - **Temperatura** (0-2): Control de creatividad vs precisiÃ³n
  - **Top-P** (0-1): Sampling de probabilidad nÃºcleo
  - **Top-K** (0-20): Sampling por cantidad de tokens
  - **Reasoning Effort** (minimal/low/medium/high): Nivel de anÃ¡lisis
  - **Max Tokens**: LÃ­mite de respuesta
  - **API Endpoint**: URL configurable del servidor
  - **System Prompt**: Instrucciones editables para el modelo

### 6. ğŸ® Usabilidad y Control del Chat
- âœ… **BotÃ³n "Limpiar Chat"** para resetear conversaciÃ³n
- âœ… **NavegaciÃ³n integrada** desde el header principal
- âœ… **Mensajes con timestamps** y avatares diferenciados
- âœ… **Interfaz responsive** optimizada para mÃ³viles y desktop
- âœ… **Sugerencias de uso** mostradas al iniciar

## ğŸ› ï¸ Arquitectura TÃ©cnica

### Frontend (React + TypeScript)
```
src/components/chat/
â”œâ”€â”€ ChatInterface.tsx      # Componente principal del chat
â”œâ”€â”€ ConfigurationPanel.tsx # Panel de configuraciÃ³n del LLM
```

### Backend (Node.js + Express)
```
chat-server.mjs           # Servidor de chat con respuestas inteligentes
```

### TecnologÃ­as Utilizadas
- **React 19** con TypeScript
- **TanStack Router** para navegaciÃ³n
- **TanStack Query** para gestiÃ³n de estado asÃ­ncrono
- **Redux Toolkit** para estado global
- **Tailwind CSS** para estilos
- **Express.js** para el servidor de chat
- **Lucide React** para iconografÃ­a

## ğŸš€ CÃ³mo Ejecutar el Proyecto

### 1. Instalar dependencias
```bash
npm install
```

### 2. Iniciar el servidor de desarrollo (Frontend)
```bash
npm start
# Se ejecuta en http://localhost:3000
```

### 3. Iniciar el servidor de chat (Backend)
```bash
node chat-server.mjs
# Se ejecuta en http://localhost:4000
```

### 4. Acceder al chat
- Navega a http://localhost:3000
- Haz clic en el botÃ³n "Chat IA" en el header
- Â¡Comienza a hacer preguntas sobre tus finanzas!

## ğŸ’¡ Ejemplos de Uso del Chat

### Consultas de Balance
- "Â¿CuÃ¡l es mi balance actual?"
- "Â¿CuÃ¡nto dinero tengo disponible?"

### AnÃ¡lisis de Gastos
- "Â¿En quÃ© he gastado mÃ¡s dinero?"
- "MuÃ©strame mis gastos recientes"
- "Â¿CuÃ¡les son mis patrones de gasto?"

### Consejos Financieros
- "Dame consejos para mejorar mis finanzas"
- "Â¿CÃ³mo puedo ahorrar mÃ¡s dinero?"
- "Â¿Mi ratio de gastos es saludable?"

### AnÃ¡lisis Mensual
- "Â¿CÃ³mo han sido mis finanzas este mes?"
- "Compara mis ingresos y gastos mensuales"
- "Â¿CuÃ¡l fue mi mejor mes financiero?"

## ğŸ¯ CaracterÃ­sticas Destacadas

### âœ… Implementadas
1. **Respuestas Contextualizadas**: El chat conoce tus datos reales de Walletfy
2. **AnÃ¡lisis Inteligente**: Detecta patrones y proporciona insights personalizados
3. **ConfiguraciÃ³n Avanzada**: Control total sobre el comportamiento del LLM
4. **UX Optimizada**: Interfaz moderna y estados de carga elegantes
5. **IntegraciÃ³n Perfecta**: NavegaciÃ³n fluida desde la app principal

### ğŸ”„ Punto Extra (PrÃ³xima ImplementaciÃ³n)
- **Streaming de Respuestas**: RecepciÃ³n de respuestas en tiempo real por chunks

## ğŸ“Š ValidaciÃ³n de Cumplimiento

| Requisito | Estado | Detalles |
|-----------|--------|----------|
| Interfaz de Chat Intuitiva | âœ… | DiseÃ±o moderno con avatares y timestamps |
| Motor Conversacional LLM | âœ… | Servidor personalizado con validaciones |
| ContextualizaciÃ³n de Datos | âœ… | JSON optimizado con datos de Walletfy |
| GestiÃ³n de Carga del Modelo | âœ… | Estados de carga y contexto |
| InteracciÃ³n AsÃ­ncrona | âœ… | React Query + indicadores de progreso |
| PersonalizaciÃ³n del LLM | âœ… | Panel completo de configuraciÃ³n |
| Control de Usabilidad | âœ… | Limpiar chat + navegaciÃ³n integrada |
| Streaming de Respuestas | ğŸ”„ | Preparado para implementaciÃ³n futura |

## ğŸ”§ ConfiguraciÃ³n Avanzada

El proyecto incluye validaciones completas para todos los parÃ¡metros del LLM:
- ValidaciÃ³n de rangos para temperatura, top-p, top-k
- ExclusiÃ³n mutua entre top-p y top-k
- ValidaciÃ³n de reasoning effort levels
- Timeouts adaptativos segÃºn el nivel de razonamiento

## ğŸ“ˆ PrÃ³ximas Mejoras

1. **Implementar streaming de respuestas** con Server-Sent Events
2. **IntegraciÃ³n con OpenAI API** real (actualmente usa servidor de prueba)
3. **Soporte para WebLLM** para ejecuciÃ³n local
4. **Historial de conversaciones** persistente
5. **Exportar conversaciones** en formato PDF/texto

---

**Desarrollado por**: Wellington  
**Fecha**: Septiembre 2025  
**VersiÃ³n**: 1.0.0
